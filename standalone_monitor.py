"""
Standalone News Monitor - GitHub Actionsìš©
Streamlit ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  í…”ë ˆê·¸ë¨ ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.
3ë¶„ë§ˆë‹¤ GitHub Actionsì—ì„œ ìë™ ì‹¤í–‰ë©ë‹ˆë‹¤.
"""
import pandas as pd
from datetime import datetime

# ê³µí†µ ëª¨ë“ˆ import
from news_collector import (
    KEYWORDS,
    EXCLUDE_KEYWORDS,
    MAX_ITEMS_PER_RUN,
    crawl_naver_news,
    load_news_db,
    save_news_db,
    load_sent_cache,
    save_sent_cache,
    detect_new_articles,
    send_telegram_notification,
    _naver_headers,
    _normalize_url,
    load_api_usage,
    increment_api_usage,
    check_api_quota,
    is_first_run,
    mark_initialized,
)

# í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ ì •ì˜ (1=ìµœìš°ì„ , ìˆ«ìê°€ ë‚®ì„ìˆ˜ë¡ ìš°ì„ ìˆœìœ„ ë†’ìŒ)
KEYWORD_PRIORITY = {
    "í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„": 1,  # ìµœìš°ì„ 
    "POSCO INTERNATIONAL": 1,
    "í¬ìŠ¤ì½”ì¸í„°": 1,
    "ì‚¼ì²™ë¸”ë£¨íŒŒì›Œ": 2,
    "í¬ìŠ¤ì½”ëª¨ë¹Œë¦¬í‹°ì†”ë£¨ì…˜": 2,
    "í¬ìŠ¤ì½”í”Œë¡œìš°": 2,
    "êµ¬ë™ëª¨í„°ì½”ì•„": 3,
    "êµ¬ë™ëª¨í„°ì½”ì–´": 3,
    "ë¯¸ì–€ë§ˆ LNG": 3,
    "í¬ìŠ¤ì½”": 4,  # ê°€ì¥ ë‚®ì€ ìš°ì„ ìˆœìœ„
}

# ë¡œê±° import
try:
    from logger import logger
    LOGGER_AVAILABLE = True
except ImportError:
    LOGGER_AVAILABLE = False
    print("[WARNING] logger.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œê¹… ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")


def safe_print(text: str):
    """Windows ì½˜ì†” ì¸ì½”ë”© ì˜¤ë¥˜ ë°©ì§€"""
    try:
        print(text)
    except UnicodeEncodeError:
        # ì´ëª¨ì§€ ì œê±°í•˜ê³  ì¬ì‹œë„
        text_clean = text.encode('ascii', 'ignore').decode('ascii')
        print(text_clean)


def apply_keyword_filters(df: pd.DataFrame, keyword: str) -> pd.DataFrame:
    """í‚¤ì›Œë“œë³„ í•„í„°ë§ ë¡œì§ ì ìš©"""
    if df.empty:
        return df

    # "í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„" ì •í™•í•œ ë§¤ì¹­
    if keyword == "í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„":
        def should_include(row):
            title = str(row.get("ê¸°ì‚¬ì œëª©", ""))
            description = str(row.get("ì£¼ìš”ê¸°ì‚¬ ìš”ì•½", ""))
            return "í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„" in title or "í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„" in description

        mask = df.apply(should_include, axis=1)
        df = df[mask].reset_index(drop=True)
        if not df.empty:
            safe_print(f"[MONITOR] 'í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„' ì •í™• ë§¤ì¹­: {len(df)}ê±´")

    # "í¬ìŠ¤ì½”ëª¨ë¹Œë¦¬í‹°ì†”ë£¨ì…˜" ì •í™•í•œ ë§¤ì¹­
    elif keyword == "í¬ìŠ¤ì½”ëª¨ë¹Œë¦¬í‹°ì†”ë£¨ì…˜":
        def should_include(row):
            title = str(row.get("ê¸°ì‚¬ì œëª©", ""))
            description = str(row.get("ì£¼ìš”ê¸°ì‚¬ ìš”ì•½", ""))
            return "í¬ìŠ¤ì½”ëª¨ë¹Œë¦¬í‹°ì†”ë£¨ì…˜" in title or "í¬ìŠ¤ì½”ëª¨ë¹Œë¦¬í‹°ì†”ë£¨ì…˜" in description

        mask = df.apply(should_include, axis=1)
        df = df[mask].reset_index(drop=True)
        if not df.empty:
            safe_print(f"[MONITOR] 'í¬ìŠ¤ì½”ëª¨ë¹Œë¦¬í‹°ì†”ë£¨ì…˜' ì •í™• ë§¤ì¹­: {len(df)}ê±´")

    # "í¬ìŠ¤ì½”í”Œë¡œìš°" ì •í™•í•œ ë§¤ì¹­
    elif keyword == "í¬ìŠ¤ì½”í”Œë¡œìš°":
        def should_include(row):
            title = str(row.get("ê¸°ì‚¬ì œëª©", ""))
            description = str(row.get("ì£¼ìš”ê¸°ì‚¬ ìš”ì•½", ""))
            return "í¬ìŠ¤ì½”í”Œë¡œìš°" in title or "í¬ìŠ¤ì½”í”Œë¡œìš°" in description

        mask = df.apply(should_include, axis=1)
        df = df[mask].reset_index(drop=True)
        if not df.empty:
            safe_print(f"[MONITOR] 'í¬ìŠ¤ì½”í”Œë¡œìš°' ì •í™• ë§¤ì¹­: {len(df)}ê±´")

    # "í¬ìŠ¤ì½”" í‚¤ì›Œë“œ íŠ¹ë³„ ì²˜ë¦¬
    elif keyword == "í¬ìŠ¤ì½”":
        def should_include(row):
            title = str(row.get("ê¸°ì‚¬ì œëª©", ""))
            title_lower = title.lower()
            description = str(row.get("ì£¼ìš”ê¸°ì‚¬ ìš”ì•½", ""))

            # "í¬ìŠ¤ì½”" ë˜ëŠ” "posco" í¬í•¨ ì²´í¬
            if "í¬ìŠ¤ì½”" not in title and "posco" not in title_lower:
                return False

            # ë¶€ë™ì‚° í‚¤ì›Œë“œ ì œì™¸
            exclude_words = ["ì²­ì•½", "ë¶„ì–‘", "ì…ì£¼", "ì¬ê±´ì¶•", "ì •ë¹„êµ¬ì—­", "ì¸í…Œë¦¬ì–´"]
            for exclude_word in exclude_words:
                if exclude_word in title or exclude_word in description:
                    return False

            return True

        mask = df.apply(should_include, axis=1)
        df = df[mask].reset_index(drop=True)
        if not df.empty:
            safe_print(f"[MONITOR] 'í¬ìŠ¤ì½”' í•„í„°ë§ ì™„ë£Œ: {len(df)}ê±´")

    # ê¸°íƒ€ í‚¤ì›Œë“œ - ë¶€ë™ì‚° í‚¤ì›Œë“œë§Œ ì œì™¸
    else:
        exclude_words = ["ë¶„ì–‘", "ì²­ì•½", "ì…ì£¼", "ì¬ê±´ì¶•", "ì •ë¹„êµ¬ì—­"]
        def should_include(row):
            title = str(row.get("ê¸°ì‚¬ì œëª©", ""))
            description = str(row.get("ì£¼ìš”ê¸°ì‚¬ ìš”ì•½", ""))
            for exclude_word in exclude_words:
                if exclude_word in title or exclude_word in description:
                    return False
            return True

        mask = df.apply(should_include, axis=1)
        df = df[mask].reset_index(drop=True)

    return df


def main():
    """ë°±ê·¸ë¼ìš´ë“œ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ë©”ì¸ í•¨ìˆ˜"""
    error_count = 0
    total_collected = 0
    telegram_success = 0

    try:
        safe_print("=" * 80)
        safe_print(f"[MONITOR] ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        safe_print("=" * 80)

        # ì „ì†¡ ìºì‹œ ë¡œë“œ
        sent_cache = load_sent_cache()

        # API í‚¤ ì²´í¬
        headers = _naver_headers()
        api_ok = bool(headers.get("X-Naver-Client-Id") and headers.get("X-Naver-Client-Secret"))

        if not api_ok:
            safe_print("[MONITOR] âŒ API í‚¤ê°€ ì—†ì–´ ìˆ˜ì§‘ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            if LOGGER_AVAILABLE:
                logger.log_error("missing_api_key", "Naver API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return

        # ê¸°ì¡´ DB ë¡œë“œ
        existing_db = load_news_db()
        safe_print(f"[MONITOR] ê¸°ì¡´ DB ë¡œë“œ ì™„ë£Œ: {len(existing_db)}ê±´")

        # ë‰´ìŠ¤ ìˆ˜ì§‘ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
        all_news = []
        quota_exceeded = False
        num_keywords = len(KEYWORDS)
        items_per_keyword = MAX_ITEMS_PER_RUN // num_keywords

        # í˜„ì¬ API ì‚¬ìš©ëŸ‰ í™•ì¸
        current_api_usage = load_api_usage()
        safe_print(f"[MONITOR] í˜„ì¬ API ì‚¬ìš©ëŸ‰: {current_api_usage}íšŒ")
        safe_print(f"[MONITOR] ìˆ˜ì§‘ ì„¤ì •: ì´ {MAX_ITEMS_PER_RUN}ê°œ / í‚¤ì›Œë“œë‹¹ ì•½ {items_per_keyword}ê°œ")

        # í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ë³„ë¡œ ì •ë ¬
        keywords_sorted = sorted(KEYWORDS, key=lambda k: KEYWORD_PRIORITY.get(k, 999))
        safe_print(f"[MONITOR] ìš°ì„ ìˆœìœ„ ì •ë ¬: {', '.join([f'{kw}(P{KEYWORD_PRIORITY.get(kw, 999)})' for kw in keywords_sorted[:3]])}...")

        for kw in keywords_sorted:
            # API í• ë‹¹ëŸ‰ í™•ì¸ (2íšŒ í˜¸ì¶œ í•„ìš” - í‰ê·  í˜ì´ì§€ë„¤ì´ì…˜)
            if not check_api_quota(required_calls=2):
                priority = KEYWORD_PRIORITY.get(kw, 999)

                # ìš°ì„ ìˆœìœ„ê°€ ë‚®ì€ í‚¤ì›Œë“œëŠ” ìŠ¤í‚µ
                if priority >= 3:
                    safe_print(f"[MONITOR] â­ï¸ API í• ë‹¹ëŸ‰ ë¶€ì¡± - ìš°ì„ ìˆœìœ„ ë‚®ì€ í‚¤ì›Œë“œ ìŠ¤í‚µ: '{kw}' (P{priority})")
                    continue
                else:
                    safe_print(f"[MONITOR] âš ï¸ API í• ë‹¹ëŸ‰ ë¶€ì¡±í•˜ì§€ë§Œ ìš°ì„ ìˆœìœ„ ë†’ìŒ: '{kw}' (P{priority}) - ê³„ì† ìˆ˜ì§‘")

            safe_print(f"[MONITOR] í‚¤ì›Œë“œ '{kw}' ê²€ìƒ‰ ì¤‘... (ìš°ì„ ìˆœìœ„: {KEYWORD_PRIORITY.get(kw, 999)})")
            df_kw = crawl_naver_news(kw, max_items=items_per_keyword, sort="date")

            # API ì‚¬ìš©ëŸ‰ ì¦ê°€
            current_api_usage = increment_api_usage(calls=2)

            # API í• ë‹¹ëŸ‰ ì´ˆê³¼ ì²´í¬
            if df_kw.attrs.get('quota_exceeded', False):
                safe_print(f"[MONITOR] âš ï¸ API í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°ì§€ - ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ë‹¨")
                quota_exceeded = True
                if LOGGER_AVAILABLE:
                    logger.log_error("api_quota_exceeded", "Naver API í• ë‹¹ëŸ‰ ì´ˆê³¼")
                error_count += 1
                break

            # í‚¤ì›Œë“œë³„ í•„í„°ë§ ì ìš©
            df_kw = apply_keyword_filters(df_kw, kw)

            if not df_kw.empty:
                all_news.append(df_kw)
                total_collected += len(df_kw)
                safe_print(f"[MONITOR] '{kw}': {len(df_kw)}ê±´ ìˆ˜ì§‘")

                # ìˆ˜ì§‘ ë¡œê¹…
                if LOGGER_AVAILABLE:
                    logger.log_collection(kw, len(df_kw), api_calls=2)

        # API í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ì²˜ë¦¬
        if quota_exceeded:
            safe_print(f"[MONITOR] âŒ API í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
            safe_print(f"[MONITOR] ğŸ’¡ ë§¤ì¼ ìì •(KST) ì´í›„ í• ë‹¹ëŸ‰ ì¬ì„¤ì •")
            return

        # í†µí•© ì •ë¦¬ & ì €ì¥
        df_new = pd.concat(all_news, ignore_index=True) if all_news else pd.DataFrame()
        if not df_new.empty:
            safe_print(f"[MONITOR] ì´ ìˆ˜ì§‘: {len(df_new)}ê±´")

            # ë‚ ì§œìˆœ ì •ë ¬
            df_new["ë‚ ì§œ_datetime"] = pd.to_datetime(df_new["ë‚ ì§œ"], errors="coerce")
            df_new = df_new.sort_values("ë‚ ì§œ_datetime", ascending=False, na_position="last").reset_index(drop=True)
            df_new = df_new.drop("ë‚ ì§œ_datetime", axis=1)

            # ì¤‘ë³µ ì œê±°
            key = df_new["URL"].where(df_new["URL"].astype(bool), df_new["ê¸°ì‚¬ì œëª©"] + "|" + df_new["ë‚ ì§œ"])
            df_new = df_new.loc[~key.duplicated()].reset_index(drop=True)

            # ê¸°ì¡´ DBì™€ ë³‘í•©
            merged = pd.concat([df_new, existing_db], ignore_index=True) if not existing_db.empty else df_new
            merged = merged.drop_duplicates(subset=["URL", "ê¸°ì‚¬ì œëª©"], keep="first").reset_index(drop=True)
            if not merged.empty:
                merged["ë‚ ì§œ"] = pd.to_datetime(merged["ë‚ ì§œ"], errors="coerce")
                merged = merged.sort_values("ë‚ ì§œ", ascending=False, na_position="last").reset_index(drop=True)
                merged["ë‚ ì§œ"] = merged["ë‚ ì§œ"].dt.strftime("%Y-%m-%d %H:%M")

            # ì‹ ê·œ ê¸°ì‚¬ ê°ì§€
            new_articles = detect_new_articles(existing_db, df_new, sent_cache)

            # DB ë¨¼ì € ì €ì¥
            save_news_db(merged)
            safe_print(f"[MONITOR] âœ… DB ì €ì¥ ì™„ë£Œ: ì´ {len(merged)}ê±´")

            # í…”ë ˆê·¸ë¨ ì•Œë¦¼ (ê¸°ì¡´ DBê°€ ë¹„ì–´ìˆì§€ ì•Šì„ ë•Œë§Œ)
            if new_articles and not existing_db.empty:
                safe_print(f"[MONITOR] âœ… ì‹ ê·œ ê¸°ì‚¬ {len(new_articles)}ê±´ ê°ì§€ - í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡")
                sent_cache_before = len(sent_cache)
                sent_cache = send_telegram_notification(new_articles, sent_cache)
                telegram_success = len(sent_cache) - sent_cache_before

                # í…”ë ˆê·¸ë¨ ë¡œê¹…
                if LOGGER_AVAILABLE:
                    failed = len(new_articles) - telegram_success
                    logger.log_telegram(telegram_success, failed, len(new_articles))

            elif new_articles:
                safe_print(f"[MONITOR] â­ï¸ ì‹ ê·œ ê¸°ì‚¬ {len(new_articles)}ê±´ ê°ì§€ - ì²« ì‹¤í–‰ì´ë¯€ë¡œ ì•Œë¦¼ ìŠ¤í‚µ")
                # ì²« ì‹¤í–‰ì—ì„œë„ ìºì‹œì— ì¶”ê°€
                for article in new_articles:
                    url = article.get("link", "")
                    if url:
                        sent_cache.add(url)
                        sent_cache.add(_normalize_url(url))
                safe_print(f"[MONITOR] ì‹ ê·œ ê¸°ì‚¬ {len(new_articles)}ê±´ì„ ìºì‹œì— ì¶”ê°€")

            safe_print(f"[MONITOR] âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        else:
            safe_print(f"[MONITOR] â„¹ï¸ ìƒˆë¡œ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # í•­ìƒ ìºì‹œ ì €ì¥
        safe_print(f"[MONITOR] ìºì‹œ ì €ì¥ ì¤‘... (í˜„ì¬ {len(sent_cache)}ê±´)")
        save_sent_cache(sent_cache)

        # ì‹¤í–‰ ìš”ì•½ ë¡œê¹…
        if LOGGER_AVAILABLE:
            logger.log_run_summary(
                total_articles=total_collected,
                new_articles=len(new_articles) if 'new_articles' in locals() else 0,
                telegram_sent=telegram_success,
                errors=error_count
            )
            # ì¼ì¼ í†µê³„ ì¶œë ¥
            logger.print_daily_summary()
            logger.save_daily_stats()

        safe_print("=" * 80)
        safe_print(f"[MONITOR] ì‘ì—… ì¢…ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        safe_print("=" * 80)

    except Exception as e:
        safe_print(f"[MONITOR] âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        error_details = traceback.format_exc()
        safe_print(f"[MONITOR] ìƒì„¸ ì˜¤ë¥˜:\n{error_details}")

        # ì—ëŸ¬ ë¡œê¹…
        if LOGGER_AVAILABLE:
            logger.log_error("unexpected_error", str(e), error_details)


if __name__ == "__main__":
    main()
